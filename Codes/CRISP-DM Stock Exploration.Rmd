---
output: html_document
editor_options: 
  chunk_output_type: console
---
---
title: "Stock Strategy Exploration and Automation"
author: 
- Abram Yorde
- Karen Richard
- Paul Fullenkamp
date: "October 1, 2018"
output: 
  html_document:
    theme: cerulean
    toc: true
    toc_depth: 1
    toc_float: true
---

```{r setup, include=FALSE}
######################## Functions ########################
is_installed = function(mypkg)
  is.element(mypkg, installed.packages()[, 1])
load_or_install <- function(package_names)
{
  for (package_name in package_names)
  {
    if (!is_installed(package_name))
    {
      install.packages(package_name, dependencies = TRUE)
    }
    library(
      package_name,
      character.only = TRUE,
      quietly = TRUE,
      verbose = FALSE
    )
  }
}
sourceDir <- function(path, trace = TRUE, ...) {
    for (nm in list.files(path, pattern = "\\.[RrSsQq]$")) {
       if(trace) cat(nm,":")           
       source(file.path(path, nm), ...)
       if(trace) cat("\n")
    }
}
##########################################################################
Required_Packages = c('tidyverse','installr','psych','quantmod','lubridate','dygraphs','doParallel','XML','caret','earth', 'lubridate', 'googledrive','cumstats')
load_or_install(Required_Packages)

## Checking for R updates
updateR(fast = F,
        browse_news = F,
        install_R = T,
        copy_packages = F,
        copy_Rprofile.site = T,
        keep_old_packages = F,
        update_packages = F,
        start_new_R = F,
        quit_R = T,
        print_R_versions = T,
        GUI = F,
        to_checkMD5sums = T,
        keep_install_file = F)

## Loading Required Functions
sourceDir(paste0(getwd(),'/Codes/Functions/'))

## Root Data Folder
Root_Folder = getwd()

## Disabling API Warning
options("getSymbols.yahoo.warning" = FALSE)
options("getSymbols.warning4.0" = FALSE)

## General RMD Options
Local_S = T
Local_L = F
Google_Drive_S = T
Google_Drive_L = T
Initial_Pull = T
Update_Pull = T
```

## Initial Raw Data Pull

```{r Initial Data Pull}
if(Initial_Pull){
  NASDAQ_Stocks = read.csv(paste0(Root_Folder,"/Data/NASDAQ.csv"))
  AMEX_Stocks = read.csv(paste0(Root_Folder,"/Data/AMEX.csv"))
  NYSE_Stocks = read.csv(paste0(Root_Folder,"/Data/NYSE.csv"))
  Market_Tickers = data.frame(Symbol = c("^GSPC","^IXIC","^DJI"),
                              Name = c("S&P 500","NASDAQ","Dow Jones"),
                              IPOyear = as.character(year(Sys.Date()) - 5),
                              LastSale = "1000")
  
  Total_Stocks = bind_rows(Market_Tickers,NASDAQ_Stocks) %>%
    mutate(IPOyear = as.numeric(as.character(IPOyear)),
           LastSale = as.numeric(as.character(LastSale))) %>%
    filter(!is.na(IPOyear),
           !is.na(LastSale)) %>%
    filter(IPOyear <= year(Sys.Date()) - 5,
           IPOyear >= year(Sys.Date()) - 15,
           LastSale >= 10)
  Dump = list()
  
  p = progress_estimated(n = nrow(Total_Stocks),min_time = 3)
  for(i in 1:nrow(Total_Stocks)){
    p$pause(0.1)$tick()$print()
    ticker = as.character(Total_Stocks$Symbol[i])
    
    
    stockData = try(getSymbols(
      ticker,
      src = "yahoo",
      auto.assign = FALSE) %>%
        as.data.frame() %>%
        mutate(Date = ymd(rownames(.))))
    if("try-error" %in% class(stockData)){
      Dump[[i]] = stockData
    }else{
      colnames(stockData) = c("Open","High","Low","Close","Volume","Adjusted","Date")
      stockData$Stock = ticker
      Dump[[i]] = stockData
    }
  }
  list.condition <- sapply(Dump, function(x) class(x) == "data.frame")
  output.list  <- Dump[list.condition]
  Combined_Results = plyr::ldply(output.list,data.frame)
  
  Combined_Results = Combined_Results %>%
    group_by(Stock) %>%
    na.locf() %>%
    ungroup()
  
  
  if(Local_S){
    save(Combined_Results,
         file = paste0(Root_Folder,"/Data//NASDAQ Historical.RDATA"))
  }
  if(Google_Drive_S){
    save(Combined_Results,
         file = paste0(tempdir(),'/',"NASDAQ Historical.RDATA"))
    drive_upload(media =paste0(tempdir(),'/',"NASDAQ Historical.RDATA"),
                 path = "NASDAQ Historical.RDATA")
  }
}

```

```{r Data Update}
# Takes About 15 Minutes
if(Update_Pull){
  if(Local_L){
    Ticker_Pull_Function(Location = paste0(Root_Folder,"/Data/"),Google_Drive = F)
  }
  if(Google_Drive_L){
    Ticker_Pull_Function(Google_Drive = T)
  }
}
```

```{r Market Designation}
if(Google_Drive_L){
  File = drive_download(file = "NASDAQ Historical.RDATA",
                        overwrite = T)
  load(File$local_path)
  rm(File)
}
if(Local_L){
  load(paste0(Root_Folder,"/Data/NASDAQ Historical.RDATA"))
}

## Defining MArket Directions
Market_DF = Combined_Results %>%
  filter(Stock %in% c("^GSPC","^IXIC","^DJI")) %>%
  group_by(Stock) %>%
  mutate(PR_1D = (Adjusted - lag(Adjusted,1))/lag(Adjusted,1)) %>%
  na.omit() %>%
  mutate(PR_Cum = cumsum(PR_1D),
         Indicator = runMax(PR_Cum,90),
         Delta = PR_Cum - Indicator) %>%
  na.omit() %>%
  mutate(Market_Status = as.factor(case_when(
    Delta <= -0.20 ~ "Bear",
    Delta <= -0.10 ~ "Correction",
    Delta < -0.05 ~ "Pullback",
    Delta >= -0.05 ~ "Bull"
  ))) %>%
  ungroup()

Plot_DF = Market_DF
Plot_DF[Plot_DF$Stock == "^GSPC","Stock"] = "S&P 500"
Plot_DF[Plot_DF$Stock == "^IXIC","Stock"] = "NASDAQ"
Plot_DF[Plot_DF$Stock == "^DJI","Stock"] = "Dow Jones"
Plot_DF$Market_Status = factor(Plot_DF$Market_Status, levels = c("Bull",
                                                                      "Pullback",
                                                                      "Correction",
                                                                      "Bear"))

## Plot Examining Market Direction Designation
ggplot(Plot_DF,aes(x = Date,y = PR_Cum,color = Market_Status)) +
  geom_point() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Date",
       y = "Cumulative % Return",
       color = "Market Status") +
  facet_wrap(Stock~.,nrow = 3,ncol = 1)

## Final_Indicator
Market_Ind = Market_DF %>%
  select(Date,Stock,Market_Status) %>%
  spread(key = Stock, value = Market_Status) %>%
  mutate(Market_Status = case_when(
    `^GSPC` == "Bear" | `^IXIC` == "Bear" | `^DJI` == "Bear" ~ "Bear",
    `^GSPC` == "Correction" | `^IXIC` == "Correction" | `^DJI` == "Correction" ~ "Correction",
    `^GSPC` == "Pullback" | `^IXIC` == "Pullback" | `^DJI` == "Pullback" ~ "Pullback",
    TRUE ~ "Bull"
  )) %>%
  select(Date,Market_Status)

if(Local_S){
save(Market_Ind,
     file = paste0(Root_Folder,"/Data//Market_Ind.RDATA"))
}
if(Google_Drive_S){
  save(Market_Ind,
       file = paste0(tempdir(),'/',"Market_Ind.RDATA"))
  drive_upload(media = paste0(tempdir(),'/',"Market_Ind.RDATA"),
               path = "Market_Ind.RDATA")
}
```


```{r Pool Reduction}
if(Google_Drive_L){
  File = drive_download(file = "NASDAQ Historical.RDATA",
                        overwrite = T)
  load(File$local_path)
  rm(File)
  File = drive_download(file = "Market_Ind.RDATA",
                        overwrite = T)
  load(File$local_path)
  rm(File)
}
if(Local_L){
  load(paste0(Root_Folder,"/Data/NASDAQ Historical.RDATA"))
  load(paste0(Root_Folder,"/Data//Market_Ind.RDATA"))
}

## Takes about 5 Minutes  
Start = Sys.time()
print("Initial Stat Calculation for Pool Selection")
PR_Stage = PR_Appendage(Combined_Results,parallel = T)
Sys.time() - Start

## Initial Pool Reduction
NASDAQ_Stocks = read.csv(paste0(Root_Folder,"/Data/NASDAQ.csv"))
PR_Red_1 = left_join(PR_Stage,NASDAQ_Stocks,by = c("Stock" = "Symbol")) %>%
  select(-c(X,Summary.Quote,LastSale)) %>%
  filter(Opt >= 0,
         Price_Growth >= 0,
         Volume_Trajectory >= 0) %>%
  mutate(Reward_Mean_Score = dense_rank(desc(Reward_Mean)),
         Risk_Mean_Score = dense_rank(desc(Risk_Mean)),
         Price_Growth_Score = dense_rank(desc(Price_Growth)),
         Volume_Norm_Score = dense_rank(desc(Volume_Norm))) %>%
  na.omit()

## Appending FinViz Stats
## Takes About 2 Minutes
Start = Sys.time()
storage = list()
print("Beginning Pool Selection FinViz Stat Pull")
p = progress_estimated(nrow(PR_Red_1))
for(i in 1:nrow(PR_Red_1)){
  Ticker = PR_Red_1$Stock[i]
  TMP = try(FinViz_Metric_Pull(Ticker),
            silent = T)
  storage[[i]] = TMP
  p$pause(0.5)$tick()$print()
}
Metrics = plyr::ldply(storage[sapply(storage,class) %in% "data.frame"],data.frame)
Sys.time() - Start

Pool_Results = PR_Red_1 %>%
  left_join(Metrics) %>%
  mutate(Profit.Margin = as.numeric(str_remove(Profit.Margin,"%"))/100,
         Oper..Margin = as.numeric(str_remove(Oper..Margin,"%"))/100,
         Change = as.numeric(str_remove(Change,"%"))/100,
         Price = as.numeric(as.character(Price)),
         Prev.Close = as.numeric(as.character(Prev.Close)),
         ATR = as.numeric(as.character(ATR)),
         Beta = as.numeric(as.character(Beta)),
         Perf.YTD = as.numeric(str_remove(Perf.YTD,"%"))/100,
         Perf.Year = as.numeric(str_remove(Perf.Year,"%"))/100,
         Perf.Half.Y = as.numeric(str_remove(Perf.Half.Y,"%"))/100,
         Perf.Quarter = as.numeric(str_remove(Perf.Quarter,"%"))/100,
         Perf.Month = as.numeric(str_remove(Perf.Month,"%"))/100,
         Perf.Week = as.numeric(str_remove(Perf.Week,"%"))/100,
         RSI..14. = as.numeric(as.character(RSI..14.)),
         EPS..ttm. = as.numeric(str_remove(EPS..ttm.,"%"))/100,
         EPS.next.Y = as.numeric(str_remove(EPS.next.Y,"%"))/100,
         EPS.next.Q = as.numeric(str_remove(EPS.next.Q,"%"))/100,
         EPS.this.Y = as.numeric(str_remove(EPS.this.Y,"%"))/100,
         EPS.next.Y.1 = as.numeric(str_remove(EPS.next.Y.1,"%"))/100,
         EPS.next.5Y = as.numeric(str_remove(EPS.next.5Y,"%"))/100,
         EPS.past.5Y = as.numeric(str_remove(EPS.past.5Y,"%"))/100,
         Sales.past.5Y = as.numeric(str_remove(Sales.past.5Y,"%"))/100,
         Sales.Q.Q = as.numeric(str_remove(Sales.Q.Q,"%"))/100,
         EPS.Q.Q = as.numeric(str_remove(EPS.Q.Q,"%"))/100,
         ROA = as.numeric(str_remove(ROA,"%"))/100,
         ROE = as.numeric(str_remove(ROE,"%"))/100,
         ROI = as.numeric(str_remove(ROI,"%"))/100,
         X52W.High = as.numeric(str_remove(X52W.High,"%"))/100,
         X52W.Low = as.numeric(str_remove(X52W.Low,"%"))/100,
         Target.Price = as.numeric(as.character(Target.Price)),
         Short.Ratio = as.numeric(as.character(Short.Ratio)),
         Short.Float = as.numeric(str_remove(Short.Float,"%"))/100,
         Payout = as.numeric(str_remove(Payout,"%"))/100,
         Gross.Margin = as.numeric(str_remove(Gross.Margin,"%"))/100,
         Inst.Trans = as.numeric(str_remove(Inst.Trans,"%"))/100,
         Inst.Own = as.numeric(str_remove(Inst.Own,"%"))/100,
         Insider.Trans = as.numeric(str_remove(Insider.Trans,"%"))/100,
         Insider.Own = as.numeric(str_remove(Insider.Own,"%"))/100,
         X52W.Low = as.numeric(str_remove(X52W.Low,"%"))/100,
         LT.Debt.Eq = as.numeric(as.character(LT.Debt.Eq)),
         Debt.Eq = as.numeric(as.character(Debt.Eq)),
         Current.Ratio = as.numeric(as.character(Current.Ratio)),
         Quick.Ratio = as.numeric(as.character(Quick.Ratio)),
         P.FCF = as.numeric(as.character(P.FCF)),
         P.C = as.numeric(as.character(P.C)),
         P.B = as.numeric(as.character(P.B)),
         P.S = as.numeric(as.character(P.S)),
         PEG = as.numeric(as.character(PEG)),
         Forward.P.E = as.numeric(as.character(Forward.P.E)),
         P.E = as.numeric(as.character(P.E)),
         Recom = as.numeric(as.character(Recom)),
         Employees = as.numeric(as.character(Employees)),
         Target.Price = as.numeric(as.character(Target.Price))
         ) %>%
  select(-c(Volume,Avg.Volume,Rel.Volume,SMA200,SMA50,SMA20)) %>%
  filter(Sales.Q.Q >= 0,
         Sales.past.5Y >=0,
         Profit.Margin >= 0,
         EPS.past.5Y >= 0,
         EPS.this.Y >= 0,
         EPS.next.Y >= 0,
         EPS.next.Y.1 >= 0,
         EPS.Q.Q >= 0,
         ROE >= 0.10,
         Insider.Own > 0)

Tickers = unique(Pool_Results$Stock)
for(i in 1:length(Tickers)){
  TMP = Combined_Results %>%
    filter(Stock == Tickers[i])
  p1 = ggplot(TMP,aes(x = Date,y = Adjusted)) + 
    geom_line() + 
    labs(title = paste(Tickers[i]))
  print(p1)
}

## Reducing Historical Data to Reduced Selections
Reduced_Results = Combined_Results %>%
  filter(Stock %in% Pool_Results$Stock) %>%
  left_join(Market_Ind) %>%
  na.omit()

# Saving Pool Results and Reduced Raw Data
if(Local_S){
  save(Pool_Results,Reduced_Results,
       file = paste0(Root_Folder,"/Data//Pool_Results.RDATA"))
}
if(Google_Drive_S){
  save(Pool_Results,Reduced_Results,
       file = paste0(tempdir(),'/',"Pool_Results.RDATA"))
  drive_upload(media =paste0(tempdir(),'/',"Pool_Results.RDATA"),
               path = "Pool_Results.RDATA")
}
```

## Training Set Creation

```{r Training Set Creation}
## Loading Pool Results
if(Google_Drive_L){
  File = drive_download("Pool_Results.RDATA",
                        overwrite = T)
  load(File$local_path)
  rm(File)
}
if(Local_L){
  load(file = paste0(Root_Folder,"/Data//Pool_Results.RDATA"))
}

## Building Optimized Training Set
## Takes About 3 Minute
Start = Sys.time()
Train_Set = Training_Set_Function(Reduced_Results) %>%
  na.omit()
Train_Set_Total = Training_Set_Function(Combined_Results) %>%
  na.omit()
Sys.time() - Start

## Tabulating Optimized Window Sizes
Windows = Train_Set_Total %>%
  group_by(Stock) %>%
  select(contains("Window")) %>%
  summarise_all(mean)

## Feature Selection
## Takes about 2 Minutes
Start = Sys.time()
Remove = c("Date","Adj_Smooth","Max","Days","PR","PR_1D","Market_Status")

DF = Train_Set %>%
  group_by(Stock) %>%
  nest()

Variables = DF %>%
  mutate(Variable = map(data, Variable_Importance_Reduction, Target = c("Buy"), Remove = Remove)) 

Sys.time() - Start


if(Local_S){
  save(Variables,Train_Set,Train_Set_Total,Windows,
       file = paste0(Root_Folder,"/Data/Training_Prep.RDATA"))
}
if(Google_Drive_S){
  save(Variables,Train_Set,Train_Set_Total,Windows,
       file = paste0(tempdir(),'/',"Training_Prep.RDATA"))
  drive_upload(media =paste0(tempdir(),'/',"Training_Prep.RDATA"),
               path = "Training_Prep.RDATA")
}

```


```{r Variable Importance Correction}
## Adds NA to columns where variable importance says they arent needed. 
if(Google_Drive_L){
  File = drive_download("Training_Prep.RDATA",
                        overwrite = T)
  load(File$local_path)
  rm(File)
}
if(Local_L){
  load(file = paste0(Root_Folder,"/Data/Training_Prep.RDATA"))
}

Unique = as.character(unique(Variables$Stock))

Train_Set = Train_Set %>%
  filter(Stock %in% Unique)

NAFUNCTION = function(x){x = NA}

p = progress_estimated(length(Unique))
for(i in 1:length(Unique)){
  
  idx = which(Variables$Stock %in% Unique[i])
  Vars = c(unlist(Variables$Variable[idx]),"Market_Status")
  
  Keep = Train_Set %>%
    filter(Stock == Unique[i]) %>%
    dplyr::select(Date, Stock, Buy)
  
  Temp = Train_Set %>%
    filter(Stock == Unique[i])
  Temp = Temp %>%
    mutate_if(colnames(Temp) %in% Vars == FALSE, NAFUNCTION) %>%
    dplyr::select(-Stock, -Buy, -Date)
  
  Temp = cbind(Keep, Temp)
  
  if(i == 1) {
    Comb = Temp
  }
  if(i != 1){
    Comb = rbind(Comb, Temp)
  }
  
  p$pause(0.5)$tick()$print()
}

Train = Comb

if(Google_Drive_S){
  save(Train,
       file = paste0(tempdir(),'/',"Training_Data.RDATA"))
  drive_upload(media =paste0(tempdir(),'/',"Training_Data.RDATA"),
               path = "Training_Data.RDATA")
}
if(Local_S){
  save(Train,
       file = paste0(Root_Folder,"/Data/Training_Data.RDATA"))
}
```

```{r Model Testing}
if(Google_Drive_L){
  File = drive_download("Training_Data.RDATA",
                        overwrite = T)
  load(File$local_path)
  rm(File)
}
if(Local_L){
  load(file = paste0(Root_Folder,"/Data/Training_Data.RDATA"))
}

NA_Select = function(x){sum(is.na(x)) == 0}
TMP = Train %>%
  filter(Stock == "YNDX") %>%
  select_if(NA_Select)
Train_DF = TMP %>%
  filter(Date < "2018-01-01 00:00:00") %>%
  select(-c(Date,Stock))
Test_DF = TMP %>%
  filter(Date >= "2018-01-01 00:00:00")

mod = earth(Buy~.,
          Train_DF,
          nfold = 5,
          ncross = 5,
          degree = 2,
          nk = 5)

pred_train = predict(mod,Train_DF,type = "response")
Test_DF$pred = predict(mod,Test_DF,type = "response")
ggplot(Test_DF,aes(x = Date,y = pred)) +
  geom_point() + 
  geom_point(aes(y = Buy)) + 
  geom_point(aes(y = Close))

```


```{r Modeling}
# Modeling with the crossfold function
if(Google_Drive_L){
  File = drive_download("Training_Data.RDATA",
                        overwrite = T)
  load(File$local_path)
  rm(File)
}
if(Local_L){
  load(file = paste0(Root_Folder,"/Data/Training_Data.RDATA"))
}

DF = Train %>%
  # filter(Stock == "AMZN" | Stock == "ADBE" | Stock == "AMED") %>%
  group_by(Stock) %>%
  nest()

Results= DF %>%
  mutate(model = map(data, Crossfold, start_width = 200, expand = F)) %>%
  unnest(model)

save(Results, file = "Results.RDATA")

library(dygraphs)
library(xts)

Plot = Results %>%
  filter(Stock == "ADBE")

RN = Plot$Date
rownames(Plot) =RN
Plot$Date = NULL
Plot = as.xts(Plot)

dygraph(Plot) %>%
  dySeries("Buy", color = "red", label = "Buy", strokeWidth = 2, strokePattern = "dashed") %>%
  dySeries("Buy_Pred", color = "green", label = "Prediction", strokeWidth = 2, strokePattern = "dashed")


```

