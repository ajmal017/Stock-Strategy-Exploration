---
title: "Stock Automated Methodology"
author: "Paul, Karen, Abram"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: cerulean
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
## Setting RMD Project Directory
Project_Folder = rprojroot::find_rstudio_root_file()
knitr::opts_knit$set(root.dir = Project_Folder)

## Loading / Updating COMRES Data Science Package
devtools::install_github("Emerson-Data-Science/EmersonDataScience",  
                         auth_token = "7c54299b0c824b305a01dc1eeb9a6de41fe12b23",  
                         INSTALL_opts = c('--no-multiarch'),  
                         quick = TRUE,
                         dependencies = TRUE, 
                         build = FALSE,
                         quiet = FALSE,  
                         upgrade = FALSE)
library(EmersonDataScience)

## Loading and Installing Packages if necessacary
Required_Packages = c('tidyverse','installr','psych','quantmod','lubridate','dygraphs','doParallel','XML','earth', 'googledrive','cumstats','dummy','knitr','xts','reshape2','mboost','glmnet','broom','recipes','caret','cluster','factoextra',"HiClimR")
load_or_install(Required_Packages)

## Loading Required Functions
sourceDir(paste0(Project_Folder,"/Codes/Functions"))

## Disabling API Warning
options("getSymbols.yahoo.warning" = FALSE)
options("getSymbols.warning4.0" = FALSE)

## General RMD Options
Re_Pull = T
Initial_History = F
TEST = T
```

### {.tabset}

```{r Raw Data Pull, include = F,eval = !TEST}
## Pulling Historical Data
if(Re_Pull){
  ## Fresh Historical Data Pull
  Initial_Pull()
}else{
  ## Historical Table Update
  Ticker_Pull_Function(Location = paste0(Project_Folder,"/Data/"),
                       Google_Drive = F)
}
```

#### Market Status

```{r Market Direction, echo = F, message = F, warning = F}
## Loading Historical Stock Data
load(paste0(Project_Folder,"/Data/NASDAQ Historical.RDATA"))

## Bear/Bull Calculations
Market_Ind = Market_Direction(Combined_Results)
## General Fear Calculations
Fear_Ind = Fear_Direction(Combined_Results,Market_Ind)

## Saving Market Indicators
save(Market_Ind,Fear_Ind,
     file = paste0(Project_Folder,"/Data/Market Direction.RDATA"))
```
  
```{r Appending Stats and Indicators,include = F}
## Normalizing OHLCV Values  
Start = Sys.time()
print("Initial Stat Calculation for Pool Selection")
PR_Stage = PR_Appendage(Combined_Results,parallel = T)
Sys.time() - Start

## Compairing Performance to Major Indexs
Major_Indexs = c("^GSPC","^IXIC","^DJI")
Index_Alpha_Slope = PR_Stage %>%
  filter(Stock %in% Major_Indexs) %>%
  select(Stock,Date,Close_Slope_50_Norm) %>%
  spread(Stock,Close_Slope_50_Norm) %>%
  mutate(Alpha_Slope = rowMeans(cbind(`^GSPC`,`^IXIC`,`^DJI`))) %>%
  select(Date,Alpha_Slope)

## Appending Results
PR_Stage_R2 = PR_Stage %>%
  left_join(Index_Alpha_Slope,by = "Date") %>%
  na.omit() %>%
  mutate(Pseudo_Alpha_PD = (Close_Slope_50_Norm - Alpha_Slope)/Alpha_Slope)

## Removing Dead Stocks Or Baby Stocks
Time_Stop = max(PR_Stage_R2$Date)
Time_Start = Time_Stop - 365*5
Last_Time = PR_Stage_R2 %>% 
  group_by(Stock) %>%
  summarise(Max_Time = max(Date),
            Min_Time = min(Date)) %>%
  filter(Max_Time == Time_Stop,
         Min_Time <= Time_Start)

## Calculating Technical Indicators
Stocks = unique(Last_Time$Stock)

## Spinning Up Clusters
c1 = makeCluster(detectCores())
registerDoParallel(c1)

## Parallel Execution
Results = foreach(i = 1:length(Stocks),
                  .inorder = F,
                  .packages = c("tidyverse",
                                "quantmod",
                                "lubridate",
                                "TTR"),
                  .verbose = F) %dopar% {
                    ## Subsetting Data
                    TMP = PR_Stage_R2 %>%
                      filter(Stock == Stocks[i])
                    
                    ## Calculating Technical Indicators
                    Stat_Appendage_Function(DF = TMP)
                  }

## Spinning Down Clusters
stopCluster(c1)
registerDoSEQ()

## Consolidating Results
PR_Stage_R3 = plyr::ldply(Results,data.frame)

## Saving Results
save(PR_Stage_R3,
     file = paste0(Project_Folder,"/Data/Normalized Historical and Technical Indicators.RDATA"))
```

```{r Variable Importance Reduction, include = F}
## Loading Indicator Data
load(file = paste0(Project_Folder,"/Data/Normalized Historical and Technical Indicators.RDATA"))
## Initial Data
ID_DF = PR_Stage_R3 %>%
  left_join(Market_Ind) %>%
  left_join(Fear_Ind) %>%
  mutate(WAD_Delta = WAD - lag(WAD,1),
         Close_PD = (Close - lag(Close,1))/lag(Close,1),
         SMI_Delta = (SMI - lag(SMI,1)),
         SMI_Sig_Delta = (SMI_Signal - lag(SMI_Signal,1)),
         CCI_Delta = (CCI - lag(CCI,1)))

## Defining Target Variable
PR_Stage_R4 = PR_Stage_R3 %>%
  group_by(Stock) %>%
  mutate(Adjusted_Lead = lead(Adjusted,30),
         PD_Lead = (Adjusted_Lead - Adjusted)/Adjusted,
         Target = ifelse(PD_Lead > 0,1,0)) %>%
   mutate(WAD_Delta = WAD - lag(WAD,1),
         Close_PD = (Close - lag(Close,1))/lag(Close,1),
         SMI_Delta = (SMI - lag(SMI,1)),
         SMI_Sig_Delta = (SMI_Signal - lag(SMI_Signal,1)),
         CCI_Delta = (CCI - lag(CCI,1))) %>%
  ungroup() %>%
  select(-c(PD_Lead)) %>%
  na.omit() %>%
  filter(!str_detect(Stock,"^\\^"))

## Reducing Variable Pool
Names_Profit = Variable_Importance_Reduction(DF = select(PR_Stage_R4,
                                                         -c(Open,High,Low,Close,Adjusted,
                                                            Volume,Adjusted_Lead)) %>%
                                               sample_frac(0.05),
                                             Type = 'C',
                                             Target = "Target")
Names_Futures = Variable_Importance_Reduction(DF = select(PR_Stage_R4,-c(Target,Volume)) %>%
                                               sample_frac(0.05),
                                              Type = 'R',
                                              Target = "Adjusted_Lead")

## Reducing Data
LL = function(x){median(x,na.rm = T) - 5*mad(x,na.rm = T)}
UL = function(x){median(x,na.rm = T) + 5*mad(x,na.rm = T)}
PR_Stage_R5 = PR_Stage_R4 %>%
  select(Stock,Date,Adjusted,Names_Profit$Var,Names_Futures$Var,Target,Adjusted_Lead)

## Defining Filter Columns
Filter = PR_Stage_R5 %>%
  select(Names_Profit$Var,Names_Futures$Var) %>% 
  colnames()

## Removing Outliers
for(i in Filter){
  Column = as_vector(PR_Stage_R5[,i])
  Keep = Column <= UL(Column) & Column >= LL(Column)
  PR_Stage_R5 = PR_Stage_R5[Keep,]
}

save(PR_Stage_R5,
     file = paste0(Project_Folder,"/data/Importance.RDATA"))
```

```{r Modeling,echo = F,include = F}
Split_Profit = createDataPartition(y = PR_Stage_R5$Target,p = 0.70,list = F)
Split_Futures = createDataPartition(y = PR_Stage_R5$Adjusted_Lead,p = 0.70,list = F)

Train_Profit = PR_Stage_R5[Split_Profit,c(Names_Profit$Var,"Target","Date","Adjusted","Stock")]
Test_Profit = PR_Stage_R5[-Split_Profit,c(Names_Profit$Var,"Target","Date","Adjusted","Stock")]
Train_Futures = PR_Stage_R5[Split_Futures,c(Names_Futures$Var,"Adjusted_Lead","Date","Adjusted","Stock")]
Test_Futures = PR_Stage_R5[-Split_Futures,c(Names_Futures$Var,"Adjusted_Lead","Date","Adjusted","Stock")]

Weights_Profit = scales::rescale(as.numeric(Train_Profit$Date),to = c(0,1))
Weights_Futures = scales::rescale(as.numeric(Train_Futures$Date),to = c(0,1))

Model_Profit = glm(Target~.,
                   data = select(Train_Profit,
                                 -c(Stock,Date,Adjusted)),
                   family = "quasibinomial",
                   weights = Weights_Profit)
Model_Futures = lm(Adjusted_Lead~.,
                   data = select(Train_Futures,
                                 -c(Stock,Date,Adjusted)),
                   weights = Weights_Futures)

Pred_Train = predict(Model_Profit,type = "response")
Pred_Test = predict(Model_Profit,Test_Profit,type = "response")
Cutoff = median(Pred_Test) + mad(Pred_Test)

Pred_Train[Pred_Train >= Cutoff] = 1
Pred_Train[Pred_Train < Cutoff] = 0
Pred_Test[Pred_Test >= Cutoff] = 1
Pred_Test[Pred_Test < Cutoff] = 0

Specif_Train = MLmetrics::Specificity(Pred_Train,Train_Profit$Target)
Specif_Test = MLmetrics::Specificity(Pred_Test,Test_Profit$Target)

Pred_Futures_Train = predict(Model_Futures)
Pred_Futures_Test = predict(Model_Futures,Test_Futures)

ACC_Train = MLmetrics::MAPE(Pred_Futures_Train,Train_Futures$Adjusted_Lead)
ACC_Test = MLmetrics::MAPE(Pred_Futures_Test,Test_Futures$Adjusted_Lead)


TODAY = ID_DF %>%
  filter(Date == max(Date))

Preds = predict(Model_Profit,TODAY,type = "response")
Futures = predict(Model_Futures,TODAY)

RESULT = TODAY %>%
  mutate(Prob = Preds,
         Future = Futures,
         Delta = (Future - Adjusted)/Adjusted,
         Decider = Prob + Delta,
         Stop_Loss = Adjusted - 2*ATR) %>%
  filter(Prob >= Cutoff,
         !str_detect(Stock,"^\\^")) %>%
  select(Stock,Date,Prob,Delta,Decider,Future,Adjusted,Stop_Loss,Names_Profit$Var,Names_Futures$Var) %>%
  mutate(Prob_Rank = dense_rank(-Decider)) %>%
  arrange(Prob_Rank) %>%
  filter(Prob_Rank <= quantile(Prob_Rank,Specif_Test),
         Future > Adjusted,
         Close_PD_200_Norm > 0,
         Close_PD_50_Norm > 0)

FUTURES = TODAY %>%
  mutate(Prob = Preds,
         Future = Futures,
         Delta = (Future - Adjusted)/Adjusted,
         Decider = Prob + Delta,
         Stop_Loss = Adjusted - 2*ATR) %>%
  filter(!str_detect(Stock,"^\\^")) %>%
  select(Stock,Date,Prob,Delta,Decider,Future,Adjusted,Stop_Loss,Names_Profit$Var,Names_Futures$Var) %>%
  mutate(Prob_Rank = dense_rank(-Decider)) %>%
  arrange(Prob_Rank) %>%
  filter(Future > Adjusted,
         Close_PD_200_Norm > 0,
         Close_PD_50_Norm > 0)

write_excel_csv(RESULT,path = paste0(Project_Folder,"/Predictions.csv"))
write_excel_csv(FUTURES,path = paste0(Project_Folder,"/Futures.csv"))
```

#### Potential Buy Position

```{r,echo = F}
DT::datatable(RESULT)
```

#### Stock's With Positive Futures

```{r,echo = F}
DT::datatable(FUTURES)
```

#### Performance History

```{r Perf History, echo = F,message = F,warning=F}
if(Initial_History){
  History_Table = RESULT %>%
    mutate(Market_Status = Market_Ind$Market_Status[Market_Ind$Date == max(Market_Ind$Date)],
           Market_Type = Fear_Ind$Market_Type[Fear_Ind$Date == max(Fear_Ind$Date)],
           Buy.Price = Adjusted,
           Max.Price = Adjusted,
           Buy.Date = Date,
           Stop.Loss = Stop_Loss,
           Pcent.Gain = (Adjusted - Buy.Price)/Buy.Price,
           Time.Held = NA,
           Sell.Date = NA) %>%
    select(Stock,Market_Status,Market_Type,Buy.Price,Buy.Date,Stop.Loss,Pcent.Gain,Time.Held,Sell.Date,everything())
}else{
  load(file = paste0(Project_Folder,"/Data//History_Results.RDATA"))
  Checks = which(is.na(History_Table$Sell.Date))
  Ticker_List = History_Table$Stock[Checks]
  New_Buys = which(!RESULT$Stock %in% Ticker_List)
  for(i in Checks){
    Examine = History_Table[i,]
    Current_Info = Combined_Results %>%
      filter(Stock == Examine$Stock) %>%
      arrange(desc(Date)) %>%
      head(1)
    Delta = Current_Info$Adjusted > History_Table$Max.Price[i]
    History_Table$Pcent.Gain[i] = (Current_Info$Adjusted - History_Table$Buy.Price[i])/History_Table$Buy.Price[i]
    History_Table$Time.Held[i] = difftime(Current_Info$Date,History_Table$Buy.Date[i],tz = "UTC",units = "days")
    
    History_Table$Stop.Loss[i] = ifelse(all(History_Table$Pcent.Gain[i] >= 0.10,
                                            Delta,
                                            Current_Info$Adjusted - 
                                              2*PR_Stage_R3$ATR[PR_Stage_R3$Stock == Examine$Stock & 
                                                                  PR_Stage_R3$Date == max(PR_Stage_R3$Date)] > 
                                          History_Table$Stop.Loss[i])
                                        ,
                                        Current_Info$Adjusted - 2*PR_Stage_R3$ATR[PR_Stage_R3$Stock == Examine$Stock & 
                                                                                    PR_Stage_R3$Date == max(PR_Stage_R3$Date)],
                                        History_Table$Stop.Loss[i])
    
    History_Table$Sell.Date[i] = ifelse(Current_Info$Adjusted <= History_Table$Stop.Loss[i],
                                        as.character(Current_Info$Date),
                                        NA)
  }
  if(length(New_Buys) >= 1){
    Additions = RESULT[New_Buys,] %>%
       mutate(Market_Status = Market_Ind$Market_Status[Market_Ind$Date == max(Market_Ind$Date)],
           Market_Type = Fear_Ind$Market_Type[Fear_Ind$Date == max(Fear_Ind$Date)],
           Buy.Price = Adjusted,
           Max.Price = Adjusted,
           Buy.Date = Date,
           Stop.Loss = Stop_Loss,
           Pcent.Gain = (Adjusted - Buy.Price)/Buy.Price,
           Time.Held = NA,
           Sell.Date = NA) %>%
      select(Stock,Market_Status,Market_Type,Buy.Price,Buy.Date,Stop.Loss,Pcent.Gain,Time.Held,Sell.Date,everything())
    History_Table = bind_rows(History_Table,Additions)
    }
}

# Fixing Pcent Gain for Met Stop Loss
History_Table = History_Table %>%
  mutate(Pcent.Gain = case_when(
    !is.na(Sell.Date) ~ (Stop.Loss-Buy.Price)/Buy.Price,
    TRUE ~ Pcent.Gain
  ))

# Printing Historical Returns
Historical_Return = scales::percent((sum(History_Table$Pcent.Gain * History_Table$Buy.Price))/sum(History_Table$Buy.Price))

## Interactive Table of Buy History
DT::datatable(data = History_Table,
              filter = list(position = 'top'))

# Saving Pool Results and Reduced Raw Data
save(History_Table,
       file = paste0(Project_Folder,"/Data//History_Results.RDATA"))
```

##### Historical Return `r Historical_Return`