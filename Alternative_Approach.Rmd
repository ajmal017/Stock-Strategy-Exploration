---
title: "Stock Automated Methodology"
author: "Paul, Karen, Abram"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: cerulean
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
## Setting RMD Project Directory
Project_Folder = rprojroot::find_rstudio_root_file()
knitr::opts_knit$set(root.dir = Project_Folder)

library(EmersonDataScience)

## Loading and Installing Packages if necessacary
Required_Packages = c('tidyverse','installr','psych','quantmod','lubridate','dygraphs','doParallel','XML','earth', 'googledrive','cumstats','dummy','knitr','xts','reshape2','mboost','glmnet','broom','recipes','caret','cluster','factoextra',"HiClimR")
load_or_install(Required_Packages)

## Loading Required Functions
sourceDir(paste0(Project_Folder,"/Codes/Functions"))

## Disabling API Warning
options("getSymbols.yahoo.warning" = FALSE)
options("getSymbols.warning4.0" = FALSE)

## General RMD Options
Re_Pull = F
Initial_History = F
TEST = F
```

### {.tabset}

```{r Raw Data Pull, include = F,eval = !TEST}
## Pulling Historical Data
if(Re_Pull){
  ## Fresh Historical Data Pull
  Initial_Pull()
}else{
  ## Historical Table Update
  Ticker_Pull_Function(Location = paste0(Project_Folder,"/Data/"),
                       Google_Drive = F)
}
```

#### Market Status

```{r Market Direction, echo = F, message = F, warning = F}
## Loading Historical Stock Data
load(paste0(Project_Folder,"/Data/NASDAQ Historical.RDATA"))

## Bear/Bull Calculations
Market_Ind = Market_Direction(Combined_Results)
## General Fear Calculations
Fear_Ind = Fear_Direction(Combined_Results,Market_Ind)

## Saving Market Indicators
save(Market_Ind,Fear_Ind,
     file = paste0(Project_Folder,"/Data/Market Direction.RDATA"))
```
  
```{r Appending Stats and Indicators,include = F,eval = !TEST}
## Normalizing OHLCV Values  
Start = Sys.time()
print("Initial Stat Calculation for Pool Selection")
PR_Stage = PR_Appendage(Combined_Results,parallel = T)
Sys.time() - Start

## Compairing Performance to Major Indexs
Major_Indexs = c("^GSPC","^IXIC","^DJI")
Index_Alpha_Slope = PR_Stage %>%
  filter(Stock %in% Major_Indexs) %>%
  select(Stock,Date,Close_Slope_50_Norm) %>%
  spread(Stock,Close_Slope_50_Norm) %>%
  mutate(Alpha_Slope = rowMeans(cbind(`^GSPC`,`^IXIC`,`^DJI`))) %>%
  select(Date,Alpha_Slope)

## Appending Results
PR_Stage_R2 = PR_Stage %>%
  left_join(Index_Alpha_Slope,by = "Date") %>%
  na.omit() %>%
  mutate(Pseudo_Alpha_PD = (Close_Slope_50_Norm - Alpha_Slope)/Alpha_Slope)

## Removing Dead Stocks Or Baby Stocks
Time_Stop = max(PR_Stage_R2$Date)
Time_Start = Time_Stop - 365*5
Last_Time = PR_Stage_R2 %>% 
  group_by(Stock) %>%
  summarise(Max_Time = max(Date),
            Min_Time = min(Date)) %>%
  filter(Max_Time == Time_Stop,
         Min_Time <= Time_Start)

## Calculating Technical Indicators
Stocks = unique(Last_Time$Stock)

## Spinning Up Clusters
c1 = makeCluster(detectCores())
registerDoParallel(c1)

## Parallel Execution
Results = foreach(i = 1:length(Stocks),
                  .inorder = F,
                  .packages = c("tidyverse",
                                "quantmod",
                                "lubridate",
                                "TTR"),
                  .verbose = F) %dopar% {
                    ## Subsetting Data
                    TMP = PR_Stage_R2 %>%
                      filter(Stock == Stocks[i])
                    
                    ## Calculating Technical Indicators
                    Stat_Appendage_Function(DF = TMP)
                  }

## Spinning Down Clusters
stopCluster(c1)
registerDoSEQ()

## Consolidating Results
PR_Stage_R3 = plyr::ldply(Results,data.frame)

## Saving Results
save(PR_Stage_R3,
     file = paste0(Project_Folder,"/Data/Normalized Historical and Technical Indicators.RDATA"))
```

```{r Variable Importance Reduction, include = F,eval = !TEST}
## Loading Indicator Data
load(file = paste0(Project_Folder,"/Data/Market Direction.RDATA"))
load(file = paste0(Project_Folder,"/Data/Normalized Historical and Technical Indicators.RDATA"))

## Initial Data
ID_DF = PR_Stage_R3 %>%
  left_join(Market_Ind) %>%
  left_join(Fear_Ind) %>%
  mutate(WAD_Delta = WAD - lag(WAD,1),
         Close_PD = (Close - lag(Close,1))/lag(Close,1),
         SMI_Delta = (SMI - lag(SMI,1)),
         SMI_Sig_Delta = (SMI_Signal - lag(SMI_Signal,1)),
         CCI_Delta = (CCI - lag(CCI,1)))

## Defining Target Variable
PR_Stage_R4 = PR_Stage_R3 %>%
  group_by(Stock) %>%
  mutate(Adjusted_Lead = lead(Adjusted,30),
         PD_Lead = (Adjusted_Lead - Adjusted)/Adjusted,
         Target = ifelse(PD_Lead > 0,1,0)) %>%
   mutate(WAD_Delta = WAD - lag(WAD,1),
         Close_PD = (Close - lag(Close,1))/lag(Close,1),
         SMI_Delta = (SMI - lag(SMI,1)),
         SMI_Sig_Delta = (SMI_Signal - lag(SMI_Signal,1)),
         CCI_Delta = (CCI - lag(CCI,1))) %>%
  ungroup() %>%
  select(-c(PD_Lead)) %>%
  na.omit() %>%
  filter(!str_detect(Stock,"^\\^"))

## Reducing Variable Pool
Names_Profit = Variable_Importance_Reduction(DF = select(PR_Stage_R4,
                                                         -c(Open,High,Low,Close,Adjusted,
                                                            Volume,Adjusted_Lead)) %>%
                                               sample_frac(0.05),
                                             Type = 'C',
                                             Target = "Target")
Names_Futures = Variable_Importance_Reduction(DF = select(PR_Stage_R4,-c(Target,Volume)) %>%
                                               sample_frac(0.05),
                                              Type = 'R',
                                              Target = "Adjusted_Lead")

## Reducing Data
LL = function(x){median(x,na.rm = T) - 5*mad(x,na.rm = T)}
UL = function(x){median(x,na.rm = T) + 5*mad(x,na.rm = T)}
PR_Stage_R5 = PR_Stage_R4 %>%
  select(Stock,Date,Adjusted,Names_Profit$Var,Names_Futures$Var,Target,Adjusted_Lead)

## Defining Filter Columns
Filter = PR_Stage_R5 %>%
  select(Names_Profit$Var,Names_Futures$Var) %>% 
  colnames()

## Removing Outliers
for(i in Filter){
  Column = as_vector(PR_Stage_R5[,i])
  Keep = Column <= UL(Column) & Column >= LL(Column)
  PR_Stage_R5 = PR_Stage_R5[Keep,]
}

save(PR_Stage_R5,Names_Profit,Names_Futures,
     file = paste0(Project_Folder,"/data/Importance.RDATA"))
```

```{r Modeling,echo = F,include = F,eval = !TEST}
load(file = paste0(Project_Folder,"/data/Importance.RDATA"))
Split_Profit = createDataPartition(y = PR_Stage_R5$Target,p = 0.70,list = F)
Split_Futures = createDataPartition(y = PR_Stage_R5$Adjusted_Lead,p = 0.70,list = F)

Train_Profit = PR_Stage_R5[Split_Profit,c(Names_Profit$Var,"Target","Date","Adjusted","Stock")]
Test_Profit = PR_Stage_R5[-Split_Profit,c(Names_Profit$Var,"Target","Date","Adjusted","Stock")]
Train_Futures = PR_Stage_R5[Split_Futures,c(Names_Futures$Var,"Adjusted_Lead","Date","Adjusted","Stock")]
Test_Futures = PR_Stage_R5[-Split_Futures,c(Names_Futures$Var,"Adjusted_Lead","Date","Adjusted","Stock")]

Weights_Profit = scales::rescale(as.numeric(Train_Profit$Date),to = c(0,1))
Weights_Futures = scales::rescale(as.numeric(Train_Futures$Date),to = c(0,1))

Model_Profit = glm(Target~.,
                   data = select(Train_Profit,
                                 -c(Stock,Date,Adjusted)),
                   family = "quasibinomial",
                   weights = Weights_Profit)
Model_Futures = lm(Adjusted_Lead~.,
                   data = select(Train_Futures,
                                 -c(Stock,Date,Adjusted)),
                   weights = Weights_Futures)

Pred_Train = predict(Model_Profit,type = "response")
Pred_Test = predict(Model_Profit,Test_Profit,type = "response")
Cutoff = median(Pred_Test) + mad(Pred_Test)

Pred_Train[Pred_Train >= Cutoff] = 1
Pred_Train[Pred_Train < Cutoff] = 0
Pred_Test[Pred_Test >= Cutoff] = 1
Pred_Test[Pred_Test < Cutoff] = 0

Specif_Train = MLmetrics::Specificity(Pred_Train,Train_Profit$Target)
Specif_Test = MLmetrics::Specificity(Pred_Test,Test_Profit$Target)

Pred_Futures_Train = predict(Model_Futures)
Pred_Futures_Test = predict(Model_Futures,Test_Futures)

ACC_Train = MLmetrics::MAPE(Pred_Futures_Train,Train_Futures$Adjusted_Lead)
ACC_Test = MLmetrics::MAPE(Pred_Futures_Test,Test_Futures$Adjusted_Lead)


TODAY = ID_DF %>%
  filter(Date == max(Date))

Preds = predict(Model_Profit,TODAY,type = "response")
Futures = predict(Model_Futures,TODAY)

RESULT = TODAY %>%
  mutate(Prob = Preds,
         Future = Futures,
         Delta = (Future - Adjusted)/Adjusted,
         Decider = Prob + Delta,
         Stop_Loss = Adjusted - 2*ATR) %>%
  filter(Prob >= Cutoff,
         !str_detect(Stock,"^\\^")) %>%
  select(Stock,Date,Prob,Delta,Decider,Future,Adjusted,Stop_Loss,Names_Profit$Var,Names_Futures$Var) %>%
  mutate(Prob_Rank = dense_rank(-Decider)) %>%
  arrange(Prob_Rank) %>%
  filter(Prob_Rank <= quantile(Prob_Rank,Specif_Test),
         Future > Adjusted,
         Close_PD_200_Norm > 0,
         Close_PD_50_Norm > 0)
# Appending FinViz Stats
## Takes About 2 Minutes
Start = Sys.time()
storage = list()
print("Beginning Pool Selection FinViz Stat Pull")
p = progress_estimated(nrow(RESULT))
for(i in 1:nrow(RESULT)){
  Ticker = RESULT$Stock[i]
  TMP = try(FinViz_Metric_Pull(Ticker),
            silent = T)
  storage[[i]] = TMP
  p$pause(0.5)$tick()$print()
}
Metrics = plyr::ldply(storage[sapply(storage,class) %in% "data.frame"],data.frame)
Sys.time() - Start

Pool_Results = RESULT %>%
  left_join(Metrics,by = "Stock") %>%
  mutate(Profit.Margin = as.numeric(str_remove(Profit.Margin,"%"))/100,
         Oper..Margin = as.numeric(str_remove(Oper..Margin,"%"))/100,
         Change = as.numeric(str_remove(Change,"%"))/100,
         Price = as.numeric(as.character(Price)),
         Prev.Close = as.numeric(as.character(Prev.Close)),
         Beta = as.numeric(as.character(Beta)),
         Perf.YTD = as.numeric(str_remove(Perf.YTD,"%"))/100,
         Perf.Year = as.numeric(str_remove(Perf.Year,"%"))/100,
         Perf.Half.Y = as.numeric(str_remove(Perf.Half.Y,"%"))/100,
         Perf.Quarter = as.numeric(str_remove(Perf.Quarter,"%"))/100,
         Perf.Month = as.numeric(str_remove(Perf.Month,"%"))/100,
         Perf.Week = as.numeric(str_remove(Perf.Week,"%"))/100,
         RSI..14. = as.numeric(as.character(RSI..14.)),
         EPS..ttm. = as.numeric(str_remove(EPS..ttm.,"%"))/100,
         EPS.next.Y = as.numeric(str_remove(EPS.next.Y,"%"))/100,
         EPS.next.Q = as.numeric(str_remove(EPS.next.Q,"%"))/100,
         EPS.this.Y = as.numeric(str_remove(EPS.this.Y,"%"))/100,
         EPS.next.Y.1 = as.numeric(str_remove(EPS.next.Y.1,"%"))/100,
         EPS.next.5Y = as.numeric(str_remove(EPS.next.5Y,"%"))/100,
         EPS.past.5Y = as.numeric(str_remove(EPS.past.5Y,"%"))/100,
         Sales.past.5Y = as.numeric(str_remove(Sales.past.5Y,"%"))/100,
         Sales.Q.Q = as.numeric(str_remove(Sales.Q.Q,"%"))/100,
         EPS.Q.Q = as.numeric(str_remove(EPS.Q.Q,"%"))/100,
         ROA = as.numeric(str_remove(ROA,"%"))/100,
         ROE = as.numeric(str_remove(ROE,"%"))/100,
         ROI = as.numeric(str_remove(ROI,"%"))/100,
         X52W.High = as.numeric(str_remove(X52W.High,"%"))/100,
         X52W.Low = as.numeric(str_remove(X52W.Low,"%"))/100,
         Target.Price = as.numeric(as.character(Target.Price)),
         Short.Ratio = as.numeric(as.character(Short.Ratio)),
         Short.Float = as.numeric(str_remove(Short.Float,"%"))/100,
         Payout = as.numeric(str_remove(Payout,"%"))/100,
         Gross.Margin = as.numeric(str_remove(Gross.Margin,"%"))/100,
         Inst.Trans = as.numeric(str_remove(Inst.Trans,"%"))/100,
         Inst.Own = as.numeric(str_remove(Inst.Own,"%"))/100,
         Insider.Trans = as.numeric(str_remove(Insider.Trans,"%"))/100,
         Insider.Own = as.numeric(str_remove(Insider.Own,"%"))/100,
         X52W.Low = as.numeric(str_remove(X52W.Low,"%"))/100,
         LT.Debt.Eq = as.numeric(as.character(LT.Debt.Eq)),
         Debt.Eq = as.numeric(as.character(Debt.Eq)),
         Current.Ratio = as.numeric(as.character(Current.Ratio)),
         Quick.Ratio = as.numeric(as.character(Quick.Ratio)),
         P.FCF = as.numeric(as.character(P.FCF)),
         P.C = as.numeric(as.character(P.C)),
         P.B = as.numeric(as.character(P.B)),
         P.S = as.numeric(as.character(P.S)),
         PEG = as.numeric(as.character(PEG)),
         Forward.P.E = as.numeric(as.character(Forward.P.E)),
         P.E = as.numeric(as.character(P.E)),
         Recom = as.numeric(as.character(Recom)),
         Employees = as.numeric(as.character(Employees)),
         Outlook.Growth = (Target.Price - Prev.Close)/Prev.Close,
         Volatility_Range = abs(as.numeric(str_remove(str_split_fixed(Volatility," ",2)[,2],"%")) - 
                                  as.numeric(str_remove(str_split_fixed(Volatility," ",2)[,1],"%")))) %>%
  distinct() %>%
  select(-contains("Perf")) %>%
   filter(ROE > 0,
         Sales.Q.Q > 0,
         EPS.Q.Q > 0,
         EPS.next.Y > 0)
RESULT = Pool_Results


FUTURES = TODAY %>%
  mutate(Prob = Preds,
         Future = Futures,
         Delta = (Future - Adjusted)/Adjusted,
         Decider = Prob + Delta,
         Stop_Loss = Adjusted - 2*ATR) %>%
  filter(!str_detect(Stock,"^\\^")) %>%
  select(Stock,Date,Prob,Delta,Decider,Future,Adjusted,Stop_Loss,Names_Profit$Var,Names_Futures$Var) %>%
  mutate(Prob_Rank = dense_rank(-Decider)) %>%
  arrange(Prob_Rank) %>%
  filter(Future > Adjusted,
         Close_PD_200_Norm > 0,
         Close_PD_50_Norm > 0)

SHORTS = TODAY %>%
  mutate(Prob = Preds,
         Future = Futures,
         Delta = (Future - Adjusted)/Adjusted,
         Decider = Prob + Delta,
         Stop_Loss = Adjusted - 2*ATR) %>%
  filter(!str_detect(Stock,"^\\^")) %>%
  select(Stock,Date,Prob,Delta,Decider,Future,Adjusted,Stop_Loss,Names_Profit$Var,Names_Futures$Var) %>%
  mutate(Prob_Rank = dense_rank(-Decider)) %>%
  arrange(Prob_Rank) %>%
  filter(Future < Adjusted)

write_excel_csv(RESULT,path = paste0(Project_Folder,"/Predictions.csv"))
write_excel_csv(FUTURES,path = paste0(Project_Folder,"/Futures.csv"))
write_excel_csv(SHORTS,path = paste0(Project_Folder,"/Shorts.csv"))
save(RESULT,FUTURES,SHORTS,
     file = paste0(Project_Folder,"/data/Report Outputs.RDATA"))
```

#### Potential Buy Position

```{r,echo = F}
load(file = paste0(Project_Folder,"/data/Report Outputs.RDATA"))
load(file = paste0(Project_Folder,"/Data/Normalized Historical and Technical Indicators.RDATA"))
DT::datatable(RESULT)
```

#### Monitoring Charts

```{r Charts,echo = F}
## Plotting last 6 Months of Stock Data
Tickers = unique(RESULT$Stock)
Plot_Date = max(Combined_Results$Date) - 30*3
for(i in 1:length(Tickers)){
  TMP = Combined_Results %>%
    filter(Stock == Tickers[i]) %>%
    mutate(Color = ifelse(Close > Open,"Gain","Loss"),
           Date = as_date(Date)) %>%
    melt(id.vars = c("Date","Stock","Color")) %>%
    group_by(variable) %>%
    mutate(SMA_50 = rollapply(value,
                              width = 50,
                              FUN = mean,
                              na.rm = T,
                              fill = NA,
                              align = "right"),
           SMA_200 = rollapply(value,
                              width = 200,
                              FUN = mean,
                              na.rm = T,
                              fill = NA,
                              align = "right")) %>%
    ungroup() %>%
    na.omit() %>%
    filter(Date >= Plot_Date,
           variable %in% c("Close","Volume"))
  Current_Price = TMP %>%
    filter(variable == "Close",
           Date == max(Date))
 
  
  p1 = ggplot(TMP,aes(x = Date,y = value)) +
    geom_line() +
    geom_line(aes(y = SMA_50),linetype = 3,size = 1) +
    geom_line(aes(y = SMA_200), linetype = 2,size = 1)+
    scale_x_date(breaks = scales::pretty_breaks(9)) +
    scale_color_manual(values = c("green","red")) +
    labs(title = paste0(unique(TMP$Stock)," 6 Month Performance :: Current Price = ",round(Current_Price$value,2)),
         subtitle = "Dotted Line = 50 Day SMA :: Dashed Line = 200 Day SMA :: Solid Line = Actual",
         y = "",
         x = "",
         color = "") +
    theme(legend.position = "none",
          axis.text.y = element_blank(),axis.ticks.y = element_blank()) +
    facet_wrap(variable~.,nrow = 2,scales = "free_y")
  print(p1)
}
```

#### Stock's With Positive Futures

```{r,echo = F}
DT::datatable(FUTURES)
```

#### Stock's With Negative Futures

```{r,echo = F}
DT::datatable(SHORTS)
```

#### Performance History

```{r Perf History, echo = F,message = F,warning=F}
if(Initial_History){
  History_Table = RESULT %>%
    mutate(Market_Status = Market_Ind$Market_Status[Market_Ind$Date == max(Market_Ind$Date)],
           Market_Type = Fear_Ind$Market_Type[Fear_Ind$Date == max(Fear_Ind$Date)],
           Buy.Price = Adjusted,
           Max.Price = Adjusted,
           Buy.Date = Date,
           Stop.Loss = Stop_Loss,
           Pcent.Gain = (Adjusted - Buy.Price)/Buy.Price,
           Time.Held = NA,
           Sell.Date = NA) %>%
    select(Stock,Market_Status,Market_Type,Buy.Price,Buy.Date,Stop.Loss,Pcent.Gain,Time.Held,Sell.Date,everything())
}else{
  load(file = paste0(Project_Folder,"/Data//History_Results.RDATA"))
  Checks = which(is.na(History_Table$Sell.Date))
  Ticker_List = History_Table$Stock[Checks]
  New_Buys = which(!RESULT$Stock %in% Ticker_List)
  for(i in Checks){
    Examine = History_Table[i,]
    Current_Info = Combined_Results %>%
      filter(Stock == Examine$Stock) %>%
      arrange(desc(Date)) %>%
      head(1)
    Delta = Current_Info$Adjusted > History_Table$Max.Price[i]
    History_Table$Pcent.Gain[i] = (Current_Info$Adjusted - History_Table$Buy.Price[i])/History_Table$Buy.Price[i]
    History_Table$Time.Held[i] = difftime(Current_Info$Date,History_Table$Buy.Date[i],tz = "UTC",units = "days")
    
    History_Table$Stop.Loss[i] = ifelse(all(History_Table$Pcent.Gain[i] >= 0.10,
                                            Delta,
                                            Current_Info$Adjusted - 
                                              2*PR_Stage_R3$ATR[PR_Stage_R3$Stock == Examine$Stock & 
                                                                  PR_Stage_R3$Date == max(PR_Stage_R3$Date)] > 
                                          History_Table$Stop.Loss[i])
                                        ,
                                        Current_Info$Adjusted - 2*PR_Stage_R3$ATR[PR_Stage_R3$Stock == Examine$Stock & 
                                                                                    PR_Stage_R3$Date == max(PR_Stage_R3$Date)],
                                        History_Table$Stop.Loss[i])
    
    History_Table$Sell.Date[i] = ifelse(Current_Info$Adjusted <= History_Table$Stop.Loss[i],
                                        as.character(Current_Info$Date),
                                        NA)
  }
  if(length(New_Buys) >= 1){
    Additions = RESULT[New_Buys,] %>%
       mutate(Market_Status = Market_Ind$Market_Status[Market_Ind$Date == max(Market_Ind$Date)],
           Market_Type = Fear_Ind$Market_Type[Fear_Ind$Date == max(Fear_Ind$Date)],
           Buy.Price = Adjusted,
           Max.Price = Adjusted,
           Buy.Date = Date,
           Stop.Loss = Stop_Loss,
           Pcent.Gain = (Adjusted - Buy.Price)/Buy.Price,
           Time.Held = NA,
           Sell.Date = NA) %>%
      select(Stock,Market_Status,Market_Type,Buy.Price,Buy.Date,Stop.Loss,Pcent.Gain,Time.Held,Sell.Date,everything())
    History_Table = bind_rows(History_Table,Additions)
    }
}

# Fixing Pcent Gain for Met Stop Loss
History_Table = History_Table %>%
  mutate(Pcent.Gain = case_when(
    !is.na(Sell.Date) ~ (Stop.Loss-Buy.Price)/Buy.Price,
    TRUE ~ Pcent.Gain
  ))

# Printing Historical Returns
Historical_Return = scales::percent((sum(History_Table$Pcent.Gain * History_Table$Buy.Price))/sum(History_Table$Buy.Price))

## Interactive Table of Buy History
DT::datatable(data = History_Table,
              filter = list(position = 'top'))

# Saving Pool Results and Reduced Raw Data
save(History_Table,
       file = paste0(Project_Folder,"/Data//History_Results.RDATA"))
```

##### Historical Return `r Historical_Return`